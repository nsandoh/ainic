---
layout: post
title: Lo que deberías saber del algoritmo de recomendaciones de Youtube
---

Atrás quedaron los días de que las recomendaciones de contenido visual venían exclusivamente de amigos o familiares. Actualmente las plataformas de  streaming, como Netflix, Youtube y otros, utilizan sistemas recomendadores que buscan realizar un filtro sobre una cantidad masiva de opciones, entregando a cada usuario un número reducido de opciones que serían aquellas que resultarían más relevantes para cada usuario. El 70% de los videos que los billones de usuarios de Youtube viene desde su sistema recomendador, por lo que muchos creadores se sienten interesados en su funcionamiento adaptando su contenido para parecer atractivo para la plataforma, y también de los usuarios que quieren tomar control de las recomendaciones que se les ofrecen.
![_config.yml]({{ site.baseurl }}/images/yt_kid.png)
La plataforma de streaming Youtube fue creada en 2005 y su sistema recomendador ha ido cambiando con el tiempo, adoptando nuevos objetivos y mecánismos. Inicialmente se cree que el objetivo de las recomendaciones era sumar más clicks o views, sin embargo en 2012 hizo un ajuste sobre el sistema recomendador a fin de que el objetivo de este fuera mantener al usuario más tiempo viendo el contenido, es decir las recomendaciones que se le entregaban al usuario eran aquellas que más probablemente este vería de principio a fin. Luego en 2016, youtube publicó un paper mostrando las estructuras de redes neuronales que funcionaban al interior de su sistema recomendador en la cual jugaban un rol importante el contexto particular de cada usuario, buscando tener recomendaciones más personalizadas y de esta forma predecir tanto cual sería el tiempo que el usuario vería ese contenido y cuál sería el siguiente video que vería. 
Los usuarios de Youtube tienen a su disposición 4 formas de indicarle a la plataforma que no quieren ver contenido similar, a través de los botones: No me gusta, No me interesa, Eliminar del historial o No recomendar este canal. Sin embargo, un estudio de investigadores de Mozilla que buscaba ver la efectividad de estos botones a través de la actividad de 20.000 participantes durante 7 meses, descubrió que el efecto de estos botones es insignificante, por lo que si un usuario pasó un tiempo importante viendo un contenido más allá que le indique a la plataforma que no quiere ver contenido similar el sistema recomendador de todas formas incluirá videos similares en futuras recomendaciones. La efectividad de que los botones No me gusta y no me interesa detengan malas recomendaciones, es de un 12% y un 11% respectivamente, mientras que el quitar del historial tiene una efectividad de un 29% siendo dentro de las opciones del usuario la más efectiva. El estudio especula que para el algoritmo el tiempo devisualización es más importante que la satisfacción de sus usuarios.
El hecho de que el sistema recomendador Youtube no busque la satisfacción de sus usuarios ha hecho que sumen detractores, y no es lo único que se les critica. Guillaume Chaslot, ex desarrollador del primer sistema recomendador de Youtube, desarrolló un software que simula interacciones de usuarios reales para entregar transparencia al sistema recomendador que si bien ha mostrado esbozos de su estructura de redes neuronales hay detalles ocultos que pueden influenciar la decisión de un usuario en días de elecciones. Los resultados que se pueden revisar en algotransparency.org, indican que para la campaña presidencial estadounidense de 2016, el sistema recomendador incluye 6 veces más videos que favorecían la campaña de Trump por sobre Clinton, lo cual indica que el algoritmo no estaría siendo imparcial de cara a una elección presidencial.
Los sistemas recomendadores influyen en el contenido que vemos e inconscientemente en nuestras desiciones. Si como usuarios no podemos controlar las recomendaciones que se nos entregan es importante alzar la voz para que estos sistemas actuen de forma ética con transparencia y justicia. Iniciativas como The FATML group ofrecen una guía de mejores prácticas relacionadas a sistemas de inteligencia artificial, y existen instancias como FAT Conference donde investigadores discuten acerca de transparencia, justicia y acontabilidad en sistemas tecnólogicos que forman parte de nuestro día a día.

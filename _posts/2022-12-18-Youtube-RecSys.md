---
layout: post
title: Lo que deberías saber del algoritmo de recomendaciones de Youtube
---

<p>Atrás quedaron los días en que las recomendaciones de contenido visual venían exclusivamente de amigos o familiares. Actualmente las plataformas de streaming, como Netflix, Youtube y otros, utilizan sistemas recomendadores que buscan realizar un filtro sobre una cantidad masiva de opciones, entregando a cada usuario un número reducido que serían aquellas que resultarían más relevantes para cada usuario. El 70% de las reproducciones se originan en clicks en recomendaciones, por lo que muchos creadores se sienten interesados en el funcionamiento del sistema recomendador, adaptando su contenido para hacerlo atractivo para la plataforma, y también para los usuarios que quieren tomar control de lo que se les ofrece.</p>

![_config.yml]({{ site.baseurl }}/images/yt_kid.png)

<p>La plataforma de streaming Youtube fue creada en 2005 y su sistema recomendador ha ido cambiando con el tiempo, adoptando nuevos objetivos y mecánismos. Inicialmente se cree que el objetivo de las recomendaciones era sumar más clicks o views, sin embargo en 2012 hizo un ajuste sobre el sistema recomendador a fin de que el objetivo de este fuera mantener al usuario más tiempo viendo el contenido, es decir, las recomendaciones que se le entregaban al usuario eran aquellas que más probablemente este vería de principio a fin. Luego, en 2016, Youtube publicó un paper mostrando las estructuras de redes neuronales que funcionaban al interior de su sistema recomendador, en las cuales jugaba un rol importante el contexto particular de cada usuario para tener recomendaciones más personalizadas, y así predecir tanto cuál sería el tiempo que el usuario vería el contenido como cuál sería el siguiente video. </p>

<p> Los usuarios de Youtube tienen a su disposición 4 formas de indicarle a la plataforma que no quieren ver contenido similar, a través de los botones: No me gusta, No me interesa, Eliminar del historial o No recomendar este canal. Sin embargo, un estudio de investigadores de Mozilla que buscaba ver la efectividad de estos botones a través de la actividad de 20.000 participantes durante 7 meses, descubrió que el efecto de estos botones es insignificante, por lo que si un usuario pasó un tiempo importante viendo un contenido, más allá que le indique a la plataforma que no quiere ver contenido similar, el sistema recomendador de todas formas incluirá videos similares en futuras recomendaciones. La efectividad de que los botones No me gusta y No me interesa detengan malas recomendaciones, es de un 12% y un 11% respectivamente, mientras que el quitar del historial tiene una efectividad de un 29% siendo dentro de las opciones del usuario la más efectiva. El estudio especula que para el algoritmo el tiempo de visualización es más importante que la satisfacción de sus usuarios. </p>


<p>El hecho de que el sistema recomendador de Youtube no busque la satisfacción de sus usuarios ha hecho que sumen detractores, y no es lo único que se les critica. Guillaume Chaslot, ex desarrollador del primer sistema recomendador de Youtube, desarrolló un software que simula interacciones de usuarios reales para entregar transparencia al sistema recomendador que si bien ha mostrado esbozos de su estructura de redes neuronales, hay detalles ocultos que pueden influenciar la decisión de un usuario en días de elecciones. Los resultados que se pueden revisar en algotransparency.org, indican que para la campaña presidencial estadounidense de 2016, el sistema recomendador incluye 6 veces más videos que favorecen la campaña de Trump por sobre Clinton, lo cual indica que el algoritmo no estaría siendo imparcial de cara a una elección presidencial. </p>


<p>Los sistemas recomendadores influyen en el contenido que vemos e inconscientemente en nuestras decisiones. Si como usuarios no podemos controlar las recomendaciones que se nos entregan es importante alzar la voz para que estos sistemas actúen de forma ética con transparencia y justicia. Iniciativas como The FATML group ofrecen una guía de mejores prácticas relacionadas a sistemas de inteligencia artificial, y existen instancias como FAT Conference donde investigadores discuten acerca de transparencia, justicia y contabilidad en sistemas tecnológicos que forman parte de nuestro día a día.</p>
